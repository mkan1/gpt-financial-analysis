{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "with open('dataset/train.json') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "dataset = np.array([\n",
    "    ('\\n'.join(data['pre_text'] \n",
    "                + data['post_text'] \n",
    "                + [json.dumps(data['table_ori']), json.dumps(data['table'])]) \n",
    "     + '\\n' + data['qa']['question'], \n",
    "     data['qa']['answer'])\n",
    "    for data in data_dict\n",
    "])\n",
    "\n",
    "# Remove questions without an answer\n",
    "clean_dataset = np.array([(p, c) for (p, c) in dataset if c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "with open('formatted_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"prompt\", \"completion\"])  # write header\n",
    "    writer.writerows(clean_dataset)  # write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 6203 prompt-completion pairs\n",
      "- There are 47 duplicated prompt-completion sets. These are rows: [1511, 1786, 1863, 1899, 1915, 2067, 2360, 2701, 2886, 2995, 3103, 3351, 3372, 3426, 3461, 3493, 3585, 3715, 3719, 3740, 3759, 3773, 3799, 3906, 3908, 3923, 3971, 4035, 4041, 4229, 4332, 4451, 4638, 4700, 4728, 4745, 4912, 4913, 5030, 5175, 5273, 5324, 5367, 5419, 5451, 5484, 5511]\n",
      "- There are 45 examples that are very long. These are rows: [66, 413, 494, 533, 972, 1121, 1281, 1308, 1319, 1391, 1465, 1568, 1573, 1655, 1975, 2137, 2140, 2223, 2519, 2799, 2912, 2923, 2963, 3249, 3282, 3534, 3947, 4018, 4194, 4244, 4270, 4297, 4343, 4413, 4633, 5702, 5704, 5795, 5876, 5929, 5969, 5992, 6023, 6167, 6189]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert CSV into format usable by GPT\n",
    "!openai tools fine_tunes.prepare_data -f \"formatted_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "with open('dataset/test.json') as f:\n",
    "    valid_data_dict = json.load(f)\n",
    "\n",
    "valid_dataset = np.array([\n",
    "    ('\\n'.join(data['pre_text'] \n",
    "                + data['post_text'] \n",
    "                + [json.dumps(data['table_ori']), json.dumps(data['table'])]) \n",
    "     + '\\n' + data['qa']['question'], \n",
    "     data['qa']['answer'])\n",
    "    for data in valid_data_dict\n",
    "])\n",
    "\n",
    "# Remove questions without an answer\n",
    "clean_valid_dataset = np.array([(p, c) for (p, c) in valid_dataset if c])\n",
    "\n",
    "# Save to CSV\n",
    "with open('formatted_valid_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"prompt\", \"completion\"])  # write header\n",
    "    writer.writerows(clean_valid_dataset)  # write data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 1133 prompt-completion pairs\n",
      "- There are 9 duplicated prompt-completion sets. These are rows: [222, 264, 535, 662, 755, 760, 951, 953, 957]\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "- [Recommended] Remove 9 duplicate rows [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert CSV into format usable by GPT\n",
    "!openai tools fine_tunes.prepare_data -f \"formatted_valid_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"api_key.txt\", \"r\")\n",
    "api_key = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-mjKGzWqB6QJgbR337S2mQTgf at 0x7fe478362900> JSON: {\n",
       "  \"bytes\": 28792529,\n",
       "  \"created_at\": 1684274350,\n",
       "  \"filename\": \"file\",\n",
       "  \"id\": \"file-mjKGzWqB6QJgbR337S2mQTgf\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_upload_response = openai.File.create(\n",
    "  file=open(\"formatted_data_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "training_file_id = training_upload_response.id\n",
    "training_upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-wJevgYfAUGFx50S5xR4Y9Od8 at 0x7fe4f8459c20> JSON: {\n",
       "  \"bytes\": 5219225,\n",
       "  \"created_at\": 1684274410,\n",
       "  \"filename\": \"file\",\n",
       "  \"id\": \"file-wJevgYfAUGFx50S5xR4Y9Od8\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_upload_response = openai.File.create(\n",
    "  file=open(\"formatted_valid_data_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "valid_file_id = valid_upload_response.id\n",
    "valid_upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-PzwpGKewlzXC1fDppl3IAiin at 0x7fe4bb475180> JSON: {\n",
       "  \"created_at\": 1684274446,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1684274446,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-PzwpGKewlzXC1fDppl3IAiin\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": null,\n",
       "    \"learning_rate_multiplier\": null,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.01\n",
       "  },\n",
       "  \"id\": \"ft-PzwpGKewlzXC1fDppl3IAiin\",\n",
       "  \"model\": \"ada\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-rSvnkirO3SMFhS8NAtAozdxK\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"pending\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 28792529,\n",
       "      \"created_at\": 1684274350,\n",
       "      \"filename\": \"file\",\n",
       "      \"id\": \"file-mjKGzWqB6QJgbR337S2mQTgf\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1684274446,\n",
       "  \"validation_files\": [\n",
       "    {\n",
       "      \"bytes\": 5219225,\n",
       "      \"created_at\": 1684274410,\n",
       "      \"filename\": \"file\",\n",
       "      \"id\": \"file-wJevgYfAUGFx50S5xR4Y9Od8\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_response = openai.FineTune.create(training_file=training_file_id, validation_file=valid_file_id, model=\"ada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ft-PzwpGKewlzXC1fDppl3IAiin.\n",
      "Training Response: {\n",
      "  \"created_at\": 1684274446,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"created_at\": 1684274446,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-PzwpGKewlzXC1fDppl3IAiin\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": null,\n",
      "    \"learning_rate_multiplier\": null,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.01\n",
      "  },\n",
      "  \"id\": \"ft-PzwpGKewlzXC1fDppl3IAiin\",\n",
      "  \"model\": \"ada\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"organization_id\": \"org-rSvnkirO3SMFhS8NAtAozdxK\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"pending\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"bytes\": 28792529,\n",
      "      \"created_at\": 1684274350,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-mjKGzWqB6QJgbR337S2mQTgf\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1684274446,\n",
      "  \"validation_files\": [\n",
      "    {\n",
      "      \"bytes\": 5219225,\n",
      "      \"created_at\": 1684274410,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-wJevgYfAUGFx50S5xR4Y9Od8\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Training Status: pending\n"
     ]
    }
   ],
   "source": [
    "job_id = fine_tune_response[\"id\"]\n",
    "status = fine_tune_response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {fine_tune_response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ft-PzwpGKewlzXC1fDppl3IAiin\n",
      "2023-05-17 00:00:46 Created fine-tune: ft-PzwpGKewlzXC1fDppl3IAiin\n",
      "2023-05-17 00:03:12 Fine-tune costs $10.10\n",
      "2023-05-17 00:03:12 Fine-tune enqueued. Queue number: 12\n",
      "2023-05-17 00:10:08 Fine-tune is in the queue. Queue number: 11\n",
      "2023-05-17 00:10:09 Fine-tune is in the queue. Queue number: 10\n",
      "2023-05-17 00:10:55 Fine-tune is in the queue. Queue number: 9\n",
      "2023-05-17 00:12:13 Fine-tune is in the queue. Queue number: 8\n",
      "2023-05-17 00:12:15 Fine-tune is in the queue. Queue number: 7\n",
      "2023-05-17 00:12:49 Fine-tune is in the queue. Queue number: 6\n",
      "2023-05-17 00:14:04 Fine-tune is in the queue. Queue number: 5\n",
      "2023-05-17 00:14:22 Fine-tune is in the queue. Queue number: 4\n",
      "2023-05-17 00:14:22 Fine-tune is in the queue. Queue number: 3\n",
      "2023-05-17 00:14:24 Fine-tune is in the queue. Queue number: 2\n",
      "2023-05-17 00:14:25 Fine-tune is in the queue. Queue number: 1\n",
      "2023-05-17 00:14:26 Fine-tune is in the queue. Queue number: 0\n",
      "2023-05-17 00:14:48 Fine-tune started\n",
      "2023-05-17 00:26:49 Completed epoch 1/4\n",
      "2023-05-17 00:50:12 Completed epoch 3/4\n",
      "2023-05-17 01:02:15 Uploaded model: ada:ft-personal-2023-05-16-23-02-15\n",
      "2023-05-17 01:02:17 Uploaded result file: file-YQBffVtwQBXa3tGBB1mPgzXi\n",
      "2023-05-17 01:02:17 Fine-tune succeeded\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "\tstatus = openai.FineTune.retrieve(job_id).status\n",
    "\tprint(f\"Stream interrupted. Job is still {status}.\")\n",
    "\treturn\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = openai.FineTune.stream_events(job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "    \tprint(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "except Exception:\n",
    "\tprint(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune job ft-PzwpGKewlzXC1fDppl3IAiin finished with status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 1 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "\tprint(f'Job not in terminal status: {status}. Waiting.')\n",
    "\twhile status not in [\"succeeded\", \"failed\"]:\n",
    "\t\ttime.sleep(2)\n",
    "\t\tstatus = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "\t\tprint(f'Status: {status}')\n",
    "else:\n",
    "\tprint(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ada:ft-personal-2023-05-16-23-02-15'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_response = openai.FineTune.retrieve(job_id)\n",
    "fine_tuned_model = retrieve_response.fine_tuned_model\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -184\\n\\n###\\n\\n -17\\n\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prompt = '''entergy corporation and subsidiaries management 2019s financial discussion and analysis a result of the entergy louisiana and entergy gulf states louisiana business combination , results of operations for 2015 also include two items that occurred in october 2015 : 1 ) a deferred tax asset and resulting net increase in tax basis of approximately $ 334 million and 2 ) a regulatory liability of $ 107 million ( $ 66 million net-of-tax ) as a result of customer credits to be realized by electric customers of entergy louisiana , consistent with the terms of the stipulated settlement in the business combination proceeding .\n",
    "see note 2 to the financial statements for further discussion of the business combination and customer credits .\n",
    "results of operations for 2015 also include the sale in december 2015 of the 583 mw rhode island state energy center for a realized gain of $ 154 million ( $ 100 million net-of-tax ) on the sale and the $ 77 million ( $ 47 million net-of-tax ) write-off and regulatory charges to recognize that a portion of the assets associated with the waterford 3 replacement steam generator project is no longer probable of recovery .\n",
    "see note 14 to the financial statements for further discussion of the rhode island state energy center sale .\n",
    "see note 2 to the financial statements for further discussion of the waterford 3 write-off .\n",
    "results of operations for 2014 include $ 154 million ( $ 100 million net-of-tax ) of charges related to vermont yankee primarily resulting from the effects of an updated decommissioning cost study completed in the third quarter 2014 along with reassessment of the assumptions regarding the timing of decommissioning cash flows and severance and employee retention costs .\n",
    "see note 14 to the financial statements for further discussion of the charges .\n",
    "results of operations for 2014 also include the $ 56.2 million ( $ 36.7 million net-of-tax ) write-off in 2014 of entergy mississippi 2019s regulatory asset associated with new nuclear generation development costs as a result of a joint stipulation entered into with the mississippi public utilities staff , subsequently approved by the mpsc , in which entergy mississippi agreed not to pursue recovery of the costs deferred by an mpsc order in the new nuclear generation docket .\n",
    "see note 2 to the financial statements for further discussion of the new nuclear generation development costs and the joint stipulation .\n",
    "net revenue utility following is an analysis of the change in net revenue comparing 2015 to 2014 .\n",
    "amount ( in millions ) .\n",
    "the retail electric price variance is primarily due to : 2022 formula rate plan increases at entergy louisiana , as approved by the lpsc , effective december 2014 and january 2015 ; 2022 an increase in energy efficiency rider revenue primarily due to increases in the energy efficiency rider at entergy arkansas , as approved by the apsc , effective july 2015 and july 2014 , and new energy efficiency riders at entergy louisiana and entergy mississippi that began in the fourth quarter 2014 ; and 2022 an annual net rate increase at entergy mississippi of $ 16 million , effective february 2015 , as a result of the mpsc order in the june 2014 rate case .\n",
    "see note 2 to the financial statements for a discussion of rate and regulatory proceedings. .\n",
    "[[\"\", \"Amount (In Millions)\"], [\"2014 net revenue\", \"$5,735\"], [\"Retail electric price\", \"187\"], [\"Volume/weather\", \"95\"], [\"Waterford 3 replacement steam generator provision\", \"(32)\"], [\"MISO deferral\", \"(35)\"], [\"Louisiana business combination customer credits\", \"(107)\"], [\"Other\", \"(14)\"], [\"2015 net revenue\", \"$5,829\"]]\n",
    "[[\"\", \"amount ( in millions )\"], [\"2014 net revenue\", \"$ 5735\"], [\"retail electric price\", \"187\"], [\"volume/weather\", \"95\"], [\"waterford 3 replacement steam generator provision\", \"-32 ( 32 )\"], [\"miso deferral\", \"-35 ( 35 )\"], [\"louisiana business combination customer credits\", \"-107 ( 107 )\"], [\"other\", \"-14 ( 14 )\"], [\"2015 net revenue\", \"$ 5829\"]]\n",
    "what is the net change in net revenue during 2015 for entergy corporation?\\n\\n###\\n\\n'''\n",
    "\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=10,\n",
    "  temperature=0\n",
    ")\n",
    "answer['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -21.0%\\n\\n###\\n\\n -'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prompt = '''undesignated hedges was $ 41.2 million and $ 42.1 million , respectively .\n",
    "the fair value of these hedging instruments in the company 2019s consolidated balance sheets as of october 29 , 2011 and october 30 , 2010 was immaterial .\n",
    "interest rate exposure management 2014 on june 30 , 2009 , the company entered into interest rate swap transactions related to its outstanding 5.0% ( 5.0 % ) senior unsecured notes where the company swapped the notional amount of its $ 375 million of fixed rate debt at 5.0% ( 5.0 % ) into floating interest rate debt through july 1 , 2014 .\n",
    "under the terms of the swaps , the company will ( i ) receive on the $ 375 million notional amount a 5.0% ( 5.0 % ) annual interest payment that is paid in two installments on the 1st of every january and july , commencing january 1 , 2010 through and ending on the maturity date ; and ( ii ) pay on the $ 375 million notional amount an annual three month libor plus 2.05% ( 2.05 % ) ( 2.42% ( 2.42 % ) as of october 29 , 2011 ) interest payment , payable in four installments on the 1st of every january , april , july and october , commencing on october 1 , 2009 and ending on the maturity date .\n",
    "the libor- based rate is set quarterly three months prior to the date of the interest payment .\n",
    "the company designated these swaps as fair value hedges .\n",
    "the fair value of the swaps at inception was zero and subsequent changes in the fair value of the interest rate swaps were reflected in the carrying value of the interest rate swaps on the balance sheet .\n",
    "the carrying value of the debt on the balance sheet was adjusted by an equal and offsetting amount .\n",
    "the gain or loss on the hedged item ( that is , the fixed-rate borrowings ) attributable to the hedged benchmark interest rate risk and the offsetting gain or loss on the related interest rate swaps for fiscal year 2011 and fiscal year 2010 were as follows : statement of income .\n",
    "the amounts earned and owed under the swap agreements are accrued each period and are reported in interest expense .\n",
    "there was no ineffectiveness recognized in any of the periods presented .\n",
    "the market risk associated with the company 2019s derivative instruments results from currency exchange rate or interest rate movements that are expected to offset the market risk of the underlying transactions , assets and liabilities being hedged .\n",
    "the counterparties to the agreements relating to the company 2019s derivative instruments consist of a number of major international financial institutions with high credit ratings .\n",
    "based on the credit ratings of our counterparties as of october 29 , 2011 , we do not believe that there is significant risk of nonperformance by them .\n",
    "furthermore , none of the company 2019s derivative transactions are subject to collateral or other security arrangements and none contain provisions that are dependent on the company 2019s credit ratings from any credit rating agency .\n",
    "while the contract or notional amounts of derivative financial instruments provide one measure of the volume of these transactions , they do not represent the amount of the company 2019s exposure to credit risk .\n",
    "the amounts potentially subject to credit risk ( arising from the possible inability of counterparties to meet the terms of their contracts ) are generally limited to the amounts , if any , by which the counterparties 2019 obligations under the contracts exceed the obligations of the company to the counterparties .\n",
    "as a result of the above considerations , the company does not consider the risk of counterparty default to be significant .\n",
    "the company records the fair value of its derivative financial instruments in the consolidated financial statements in other current assets , other assets or accrued liabilities , depending on their net position , regardless of the purpose or intent for holding the derivative contract .\n",
    "changes in the fair value of the derivative financial instruments are either recognized periodically in earnings or in shareholders 2019 equity as a component of oci .\n",
    "changes in the fair value of cash flow hedges are recorded in oci and reclassified into earnings when the underlying contract matures .\n",
    "changes in the fair values of derivatives not qualifying for hedge accounting are reported in earnings as they occur .\n",
    "the total notional amounts of derivative instruments designated as hedging instruments as of october 29 , 2011 and october 30 , 2010 were $ 375 million of interest rate swap agreements accounted for as fair value hedges and $ 153.7 million and $ 139.9 million , respectively , of cash flow hedges denominated in euros , british pounds and analog devices , inc .\n",
    "notes to consolidated financial statements 2014 ( continued ) .\n",
    "[[\"Statement of Income\", \"October 29, 2011\", \"October 30, 2010\"], [\"Classification\", \"Loss on Swaps\", \"Gain on Note\", \"Net Income Effect\", \"Gain on Swaps\", \"Loss on Note\", \"Net Income Effect\"], [\"Other income\", \"$(4,614)\", \"$4,614\", \"$\\u2014\", \"$20,692\", \"$(20,692)\", \"$\\u2014\"]]\n",
    "[[\"statement of income classification\", \"statement of income loss on swaps\", \"statement of income gain on note\", \"statement of income net income effect\", \"statement of income gain on swaps\", \"loss on note\", \"net income effect\"], [\"other income\", \"$ -4614 ( 4614 )\", \"$ 4614\", \"$ 2014\", \"$ 20692\", \"$ -20692 ( 20692 )\", \"$ 2014\"]]\n",
    "what is the percentage change in cash flow hedges in 2011 compare to the 2010?\\n\\n###\\n\\n'''\n",
    "\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  max_tokens=10,\n",
    "  temperature=0\n",
    ")\n",
    "answer['choices'][0]['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
